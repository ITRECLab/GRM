{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No NCBI API key provided; throttling to 3 requests/second; see https://ncbiinsights.ncbi.nlm.nih.gov/2017/11/02/new-api-keys-for-the-e-utilities/\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from utils import *\n",
    "import copy\n",
    "import pprint\n",
    "import glob\n",
    "from data_load import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_withGNP = True\n",
    "ignoreLongDocument= False\n",
    "os.environ['BC6PM_dir'] = '../BC6PM'\n",
    "os.environ['pretrain_dir'] = '../BioBERT-Models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_withGNP:\n",
    "    train_data_dir = os.path.join(os.environ.get('BC6PM_dir'), 'GNormPlus', 'withAnn-Result', 'PMtask_Relations_TrainingSet_r.json')\n",
    "else:\n",
    "    train_data_dir = os.path.join(os.environ.get('BC6PM_dir'), 'json', 'PMtask_Relations_TrainingSet.json')\n",
    "with open(train_data_dir) as f:\n",
    "    train_data = json.load(f)\n",
    "documents_train = train_data['documents']\n",
    "with open(os.path.join(os.environ.get('BC6PM_dir'), 'GNormPlus', 'result', 'PMtask_Relations_TestSet_r.json')) as f:\n",
    "    eval_data = json.load(f)\n",
    "documents_eval = eval_data['documents']\n",
    "with open(os.path.join(os.environ.get('BC6PM_dir'), 'json', 'PMtask_Relations_TestSet.json')) as f:\n",
    "    eval_data_ground_truth = json.load(f)\n",
    "documents_eval_ground_truth = eval_data_ground_truth['documents']\n",
    "if ignoreLongDocument: # Ignore too long text\n",
    "    with open('pmid2tokenlen.json') as f:\n",
    "        pmid2tokenlen = json.load(f)\n",
    "    def filterLongDocu(documents):\n",
    "        documents_ = []\n",
    "        for document in documents:\n",
    "            if pmid2tokenlen.get(document['id'], 1) < 512: # some documents may not have RC instance\n",
    "                documents_.append(document)\n",
    "        return documents_\n",
    "    documents_train = filterLongDocu(documents_train)\n",
    "    documents_eval = filterLongDocu(documents_eval)\n",
    "    documents_eval_ground_truth = filterLongDocu(documents_eval_ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground Truth Relation Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.368503937007874 [0, 477, 111, 26, 15, 4, 2, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "relation_num = []\n",
    "for document in documents_eval_ground_truth:\n",
    "    relation_num.append(len(document['relations']))\n",
    "relation_num = np.array(relation_num)\n",
    "print(relation_num.mean(), [(relation_num==i).sum() for i in range(0,10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relationFilter(documents, confidence_threshold = 0.5, at_least = 0, at_most = 4):\n",
    "    documents_rtn = copy.deepcopy(documents)\n",
    "    for i, document in enumerate(documents):\n",
    "        documents_rtn[i]['relations'] = []\n",
    "        relations =  sorted(document['relations'], key=lambda relation: relation['infons']['confidence'], reverse = True)\n",
    "        for j, relation in enumerate(relations):\n",
    "            if relation['infons']['confidence']  > th_conf:\n",
    "                 documents_rtn[i]['relations'].append(relation)\n",
    "        if len(documents_rtn[i]['relations']) < at_least and len(relations)>0:\n",
    "            documents_rtn[i]['relations'] = [relations[:at_least]]\n",
    "        if len(documents_rtn[i]['relations']) > at_most and at_most > 0:\n",
    "            documents_rtn[i]['relations'] = relations[:at_most]\n",
    "    return documents_rtn\n",
    "def countDocumentNums(documents_pred_all_relation, gold_standard_relations, confidence_threshold = 0.5):\n",
    "    \"\"\"\n",
    "    if `documents` is `documents_filtered` :\n",
    "    return (pred_positive_num, true_positive_num, false_positive_num, relation2PredResult) \n",
    "    if `documents` is `documents_all_relations`:\n",
    "    return (pred_positive_num, label_1_num, label_0_num, relation2GroundTruthLabel)\n",
    "    \"\"\"\n",
    "    pred_pos = 0\n",
    "    label_1_num_or_tp_num = 0\n",
    "    label_0_num_or_fp_num = 0\n",
    "    relation2Result = {}\n",
    "    for document in documents_pred_all_relation:\n",
    "        for relation in document['relations']:\n",
    "            if  relation['infons']['confidence'] >= confidence_threshold:\n",
    "                pred_pos += 1\n",
    "\n",
    "            geneids = [relation['infons']['Gene1'], relation['infons']['Gene2']]\n",
    "            geneids.sort()\n",
    "            relation_str = 'PMID' + document['id'] + '_' + '_'.join(geneids)\n",
    "            if relation_str in gold_standard_relations:\n",
    "                label_1_num_or_tp_num += 1\n",
    "                relation2Result[relation_str] = 1\n",
    "            else:\n",
    "                label_0_num_or_fp_num += 1\n",
    "                relation2Result[relation_str] = 0\n",
    "        \n",
    "    return pred_pos, label_1_num_or_tp_num, label_0_num_or_fp_num, relation2Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post process of outputjson data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting                                          \tEpoch\tP-Ext\tR-Ext\tF1-Ext\tP-Homo\tR-Homo\tF1-Homo\n",
      "['outputjson\\\\Joint-RC-NER-SaveModel-Test-fineTune']\n",
      "27.56\t42.46\t33.42\t29.79\t45.48\t36.00\n",
      "['outputjson\\\\Joint-RC-NER-SaveModel-Test-fineTune']\n",
      "32.13\t41.08\t36.06\t34.42\t44.08\t38.66\n",
      "['outputjson\\\\Joint-RC-NER-SaveModel-Test-fineTune']\n",
      "26.38\t45.11\t33.29\t28.51\t48.49\t35.91\n",
      "['outputjson\\\\Joint-RC-NER-SaveModel-Test-fineTune']\n",
      "34.62\t38.20\t36.32\t36.84\t40.60\t38.63\n",
      "['outputjson\\\\Joint-RC-NER-SaveModel-Test-fineTune']\n",
      "26.87\t44.99\t33.65\t28.95\t48.03\t36.13\n",
      "['outputjson\\\\Joint-RC-NER-SaveModel-Test-fineTune']\n",
      "32.62\t40.62\t36.19\t35.11\t43.50\t38.86\n",
      "['outputjson\\\\Joint-RC-NER-SaveModel-Test-fineTune']\n",
      "26.87\t45.45\t33.78\t29.26\t48.84\t36.59\n",
      "['outputjson\\\\Joint-RC-NER-SaveModel-Test-fineTune']\n",
      "30.63\t39.13\t34.36\t32.85\t41.88\t36.82\n",
      "['outputjson\\\\Joint-RC-NER-SaveModel-Test-fineTune']\n",
      "37.52\t35.10\t36.27\t39.83\t37.47\t38.61\n",
      "['outputjson\\\\Joint-RC-NER-SaveModel-Test-fineTune']\n",
      "33.85\t37.51\t35.59\t36.16\t40.02\t38.00\n",
      "['outputjson\\\\Joint-RC-NER-SaveModel-Test-fineTune-GNP']\n",
      "40.42\t38.09\t39.22\t42.73\t40.26\t41.46\n",
      "['outputjson\\\\Joint-RC-NER-SaveModel-Test-fineTune-GNP']\n",
      "47.70\t28.65\t35.80\t49.81\t29.93\t37.39\n",
      "['outputjson\\\\Joint-RC-NER-SaveModel-Test-fineTune-GNP']\n",
      "44.98\t34.52\t39.06\t48.03\t36.77\t41.66\n",
      "['outputjson\\\\Joint-RC-NER-SaveModel-Test-fineTune-GNP']\n",
      "41.71\t30.96\t35.54\t44.27\t32.71\t37.63\n",
      "['outputjson\\\\Joint-RC-NER-SaveModel-Test-fineTune-GNP']\n",
      "40.32\t40.28\t40.30\t43.01\t42.81\t42.91\n",
      "['outputjson\\\\Joint-RC-NER-SaveModel-Test-fineTune-GNP']\n",
      "47.11\t33.72\t39.30\t49.84\t35.85\t41.70\n",
      "['outputjson\\\\Joint-RC-NER-SaveModel-Test-fineTune-GNP']\n",
      "48.78\t34.52\t40.43\t51.63\t36.77\t42.95\n",
      "['outputjson\\\\Joint-RC-NER-SaveModel-Test-fineTune-GNP']\n",
      "48.34\t38.55\t42.89\t51.38\t41.07\t45.65\n",
      "['outputjson\\\\Joint-RC-NER-SaveModel-Test-fineTune-GNP']\n",
      "47.36\t38.20\t42.29\t50.50\t40.84\t45.16\n",
      "['outputjson\\\\Joint-RC-NER-SaveModel-Test-fineTune-GNP']\n",
      "44.61\t40.51\t42.46\t47.56\t43.04\t45.19\n",
      "['outputjson\\\\Joint-RC-triage-Test-fineTune-GNP']\n",
      "46.06\t30.96\t37.03\t48.20\t32.60\t38.89\n",
      "['outputjson\\\\Joint-RC-triage-Test-fineTune-GNP']\n",
      "51.02\t28.65\t36.70\t53.59\t30.28\t38.70\n",
      "['outputjson\\\\Joint-RC-triage-Test-fineTune-GNP']\n",
      "50.25\t34.64\t41.01\t53.09\t36.89\t43.53\n",
      "['outputjson\\\\Joint-RC-triage-Test-fineTune-GNP']\n",
      "46.70\t37.40\t41.53\t48.92\t39.44\t43.67\n",
      "['outputjson\\\\Joint-RC-triage-Test-fineTune-GNP']\n",
      "52.26\t26.58\t35.24\t54.20\t27.73\t36.68\n",
      "['outputjson\\\\Joint-RC-triage-Test-fineTune-GNP']\n",
      "48.67\t33.60\t39.75\t51.51\t35.73\t42.19\n",
      "['outputjson\\\\Joint-RC-triage-Test-fineTune-GNP']\n",
      "42.34\t38.78\t40.48\t44.81\t41.07\t42.86\n",
      "['outputjson\\\\Joint-RC-triage-Test-fineTune-GNP']\n",
      "40.04\t41.89\t40.94\t42.89\t44.78\t43.81\n",
      "['outputjson\\\\Joint-RC-triage-Test-fineTune-GNP']\n",
      "47.22\t37.17\t41.60\t50.15\t39.79\t44.37\n",
      "['outputjson\\\\Joint-RC-triage-Test-fineTune-GNP']\n",
      "45.71\t40.51\t42.95\t48.30\t42.92\t45.45\n",
      "['outputjson\\\\RC-Only-Test-fineTune-GNP']\n",
      "35.62\t39.47\t37.45\t37.91\t42.00\t39.85\n",
      "['outputjson\\\\RC-Only-Test-fineTune-GNP']\n",
      "39.10\t38.20\t38.65\t41.60\t40.49\t41.03\n",
      "['outputjson\\\\RC-Only-Test-fineTune-GNP']\n",
      "40.18\t36.71\t38.36\t42.57\t38.86\t40.63\n",
      "['outputjson\\\\RC-Only-Test-fineTune-GNP']\n",
      "42.94\t33.60\t37.70\t45.58\t35.85\t40.13\n",
      "['outputjson\\\\RC-Only-Test-fineTune-GNP']\n",
      "40.47\t37.63\t39.00\t43.00\t39.91\t41.40\n",
      "['outputjson\\\\RC-Only-Test-fineTune-GNP']\n",
      "40.12\t38.32\t39.20\t42.68\t40.60\t41.62\n",
      "['outputjson\\\\RC-Only-Test-fineTune-GNP']\n",
      "44.44\t37.28\t40.55\t47.24\t39.68\t43.13\n",
      "['outputjson\\\\RC-Only-Test-fineTune-GNP']\n",
      "45.72\t36.25\t40.44\t48.55\t38.75\t43.10\n",
      "['outputjson\\\\RC-Only-Test-fineTune-GNP']\n",
      "37.80\t43.84\t40.60\t40.30\t46.52\t43.19\n",
      "['outputjson\\\\RC-Only-Test-fineTune-GNP']\n",
      "42.15\t39.24\t40.64\t44.65\t41.65\t43.10\n"
     ]
    }
   ],
   "source": [
    "gold_standard_ids, gold_standard_relations = JSON_Collection_Relation({'documents': documents_eval_ground_truth})\n",
    "th_conf = 0.5 # threshold of confidence\n",
    "at_least = 0  # assume the minimal/maximal number of PPIm of one single document in predicited relations at least/most  \n",
    "at_most = 4\n",
    "fileList = glob.glob('outputjson/*Test*.json')\n",
    "fileList = sorted(fileList, key = lambda f : (f.split(\".json\")[0].split(\"_\")[0], int(f.split(\".json\")[0].split(\"_\")[1])))\n",
    "print('\\t'.join(['Setting'+' '*42, 'Epoch', 'P-Ext', 'R-Ext', 'F1-Ext', 'P-Homo', 'R-Homo', 'F1-Homo']))#'R-GNP' ,\n",
    "for fileName in fileList:\n",
    "    name, idx = fileName.split(\".json\")[0].split(\"_\")\n",
    "    if int(idx) < 11:\n",
    "        print(name.split(\"/\"))\n",
    "#         print(\"{:50}\".format(name.split(\"/\")[1]), idx,sep = '\\t', end = '\\t')\n",
    "    else:\n",
    "        continue    \n",
    "    with open(fileName) as f:\n",
    "        documents_all_relations = json.load(f)['documents']\n",
    "    documents_filtered = relationFilter(documents_all_relations, confidence_threshold= th_conf, at_least = at_least, at_most = at_most)\n",
    "\n",
    "    pred_positive_num, label_1_num, label_0_num, r2truth = countDocumentNums(documents_all_relations, gold_standard_relations)\n",
    "    pred_positive_num, true_positive_num, false_positive_num, r2pred = countDocumentNums(documents_filtered, gold_standard_relations)\n",
    "\n",
    "    # R-GNP: recall of all gene pair generated by GNP, which means ignoring recognized genes.\n",
    "#     print(\"{:.2f}\".format(100*true_positive_num/label_1_num), end='\\t')\n",
    "\n",
    "    # Exact match\n",
    "    micro_precision, micro_recall, micro_f1, macro_precision, macro_recall, macro_f1 = Classification_Performance_Relation({'documents': documents_filtered}, gold_standard_ids, gold_standard_relations, homolo = False)\n",
    "    print(\"{:.2f}\\t{:.2f}\\t{:.2f}\".format(100*micro_precision, 100*micro_recall, 100*micro_f1), end = '\\t')\n",
    "    # Homolo match\n",
    "    micro_precision, micro_recall, micro_f1, macro_precision, macro_recall, macro_f1 = Classification_Performance_Relation({'documents': documents_filtered}, gold_standard_ids, gold_standard_relations, homolo = True)\n",
    "    print(\"{:.2f}\\t{:.2f}\\t{:.2f}\".format(100*micro_precision, 100*micro_recall, 100*micro_f1))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### collect result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-6e727f429465>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfileList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'outputjson/*Test*.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfileList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileList\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".json\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".json\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m targetFileName = {\n\u001b[0;32m      4\u001b[0m                \u001b[1;34m'rc_triage'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Joint-RC-triage-Test-fineTune-GNP-weightLabel_10'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                 \u001b[1;34m'rc'\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;34m'RC-Only-Test-fineTune-GNP-weightLabel_10'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'glob' is not defined"
     ]
    }
   ],
   "source": [
    "fileList = glob.glob('outputjson/*Test*.json')\n",
    "fileList = sorted(fileList, key = lambda f : (f.split(\".json\")[0].split(\"_\")[0], int(f.split(\".json\")[0].split(\"_\")[1])))\n",
    "targetFileName = {\n",
    "               'rc_triage': 'Joint-RC-triage-Test-fineTune-GNP-weightLabel_10',\n",
    "                'rc':  'RC-Only-Test-fineTune-GNP-weightLabel_10',\n",
    "                'rc_ner':  'Joint-RC-NER-SaveModel-Test-fineTune-GNP_10'\n",
    "}\n",
    "settings = sorted(targetFileName.keys())\n",
    "r2pred_dict = {}\n",
    "setting2documents_all_relations = {}\n",
    "for setting in settings:\n",
    "    path = os.path.join('outputjson', targetFileName[setting]+'.json')\n",
    "    print(setting.upper())\n",
    "    with open(path) as f:\n",
    "        setting2documents_all_relations[setting] = json.load(f)['documents']\n",
    "    documents_filtered = relationFilter(setting2documents_all_relations[setting], confidence_threshold= th_conf, at_least = at_least, at_most = at_most)\n",
    "\n",
    "    pred_positive_num, label_1_num, label_0_num, r2truth = countDocumentNums(setting2documents_all_relations[setting], gold_standard_relations)\n",
    "    print('pred_positive', pred_positive_num,'label_1', label_1_num,'label_0', label_0_num, sep = '\\t')\n",
    "    pred_positive_num, true_positive_num, false_positive_num, r2pred_dict[setting] = countDocumentNums(documents_filtered, gold_standard_relations)\n",
    "    print('pred_positive', pred_positive_num, 'tp', true_positive_num,'fp',  false_positive_num, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'settings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-499b34c08a6f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpred_result2relation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pmid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'g1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'g2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"label\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtruth_label_target\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mnotFound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'false_neg'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtruth_label_target\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'true_neg'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mpredResult\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'true'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'false'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'true_neg'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'true'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'false_neg'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'false'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'settings' is not defined"
     ]
    }
   ],
   "source": [
    "pred_result2relation = {}\n",
    "print('\\t'.join(['pmid', 'g1', 'g2', \"label\"]+settings))\n",
    "for truth_label_target in [0, 1]:\n",
    "    notFound = 'false_neg' if truth_label_target == 1 else 'true_neg'\n",
    "    predResult ={1:'true', 0: 'false', 'true_neg': 'true', 'false_neg': 'false'}\n",
    "\n",
    "    for relation_str, label in r2truth.items():\n",
    "        if label == truth_label_target:\n",
    "            pred_result = [label] + [predResult[r2pred_dict[setting].get(relation_str, notFound)] for setting in settings]\n",
    "            pred_result = tuple(pred_result)\n",
    "            print('\\t'.join(relation_str[4:].split('_')), '\\t'.join([str(x) for x in pred_result]), sep ='\\t')\n",
    "            if pred_result2relation.get(pred_result) is None:\n",
    "                    pred_result2relation[pred_result] = []\n",
    "            pred_result2relation[pred_result].append(relation_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'settings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-9415d11ee3b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m \u001b[1;34m'cnt'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpred_result_cnt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpred_result2relation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpred_result_cnt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;34m'\\t'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'settings' is not defined"
     ]
    }
   ],
   "source": [
    "print('\\t'.join(['label'] +settings+ [ 'cnt']) )\n",
    "pred_result_cnt = { k: len(v) for k, v in pred_result2relation.items()}\n",
    "for k, v in pred_result_cnt.items():\n",
    "    print( '\\t'.join([str(x) for x in k]), v, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDocumentByRelation(documents, relation_str):\n",
    "    pmid, g1,g2 = relation_str[4:].split('_')\n",
    "    for document in documents:\n",
    "        if document['id'] != pmid:\n",
    "            continue\n",
    "        for relation in document['relations']:\n",
    "            geneids = [relation['infons']['Gene1'], relation['infons']['Gene2']]\n",
    "            geneids.sort()\n",
    "            if geneids == [g1, g2]:\n",
    "                return document, relation\n",
    "def printGeneMentionInRelation(document, relation_str):\n",
    "    pmid, g1,g2 = relation_str[4:].split('_')\n",
    "    geneid2text = {}\n",
    "    geneid2text[g1] = []\n",
    "    geneid2text[g2] = []\n",
    "    for ann in (document['passages'][0]['annotations'] + document['passages'][1]['annotations']):\n",
    "        if Annotation.gettype(ann) == 'Gene':\n",
    "            geneid = Annotation.getNCBIID(ann)\n",
    "            if geneid in [g1, g2]:\n",
    "                geneid2text[geneid].append(ann['text'])\n",
    "    for id_, texts in geneid2text.items():\n",
    "        if id_ == g1:\n",
    "            print(\"GeneA\", end='\\t')\n",
    "        else:\n",
    "            print(\"GeneB\", end = '\\t')\n",
    "        print(f\"ID: {id_}\", '; Mentions:' if len(set(texts)) > 1 else 'Mention:', ','.join(set(texts)))\n",
    "\n",
    "def pprintline(text, width = 50):\n",
    "    dashNum = width - len(text)\n",
    "    offset = dashNum //2\n",
    "    print('-'*(dashNum-offset), text, '-'*(dashNum+offset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------- Result ------------------------------------------------------------------\n",
      "label\trc\trc_ner\trc_triage\n",
      "1\ttrue\ttrue\ttrue\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "(1, 'true', 'true', 'true')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c753a7cb6a1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mrelation_str\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_result2relation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mpprintline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PMID&GeneID'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (1, 'true', 'true', 'true')"
     ]
    }
   ],
   "source": [
    "# result = (0, 'false', 'true', 'true')\n",
    "result = (1, 'true', 'true', 'true')\n",
    "pprintline(\"Result\")\n",
    "print('label','\\t'.join(settings), sep = '\\t')\n",
    "print(result[0],'\\t'.join(result[1:]), sep='\\t')\n",
    "cnt = 0\n",
    "for relation_str in pred_result2relation[result]:\n",
    "    pprintline('PMID&GeneID')\n",
    "\n",
    "    setting2relation = {}\n",
    "    print( '\\t'.join(relation_str[4:].split('_')))\n",
    "    pprintline('Confidence')\n",
    "    for setting, documents_all_relations in setting2documents_all_relations.items():\n",
    "        document, relation = getDocumentByRelation( documents_all_relations, relation_str)\n",
    "        setting2relation[setting] = relation\n",
    "        print(f\"{setting:10}\", f\"{relation['infons']['confidence']:.2%}\", sep = '\\t')\n",
    "    pprintline('Gene Mention')\n",
    "    printGeneMentionInRelation(document, relation_str)\n",
    "    pprintline('Original Text')\n",
    "    print(document['passages'][0]['text'], document['passages'][1]['text'])\n",
    "    dataset = RCDataSet([document],os.environ.get('pretrain_dir') )\n",
    "    for example in dataset.examples:\n",
    "        if example.guid == relation_str[4:]:\n",
    "            pprintline('Pre-processed Text')\n",
    "            preprocessedText = example.text_a\n",
    "            for word in preprocessedText.split():\n",
    "                if word == \"Gene_A\":\n",
    "                    formated = f\"\\033[0;37;41m{word}\\033[0m\"\n",
    "                elif word == \"Gene_B\":\n",
    "                    formated = f\"\\033[0;37;40m{word}\\033[0m\"\n",
    "                elif word == \"Gene_S\":\n",
    "                    formated = f\"\\033[0;37;40m{word}\\033[0m\"\n",
    "                elif word == \"Gene_N\":\n",
    "                    formated = f\"\\033[0;30;43m{word}\\033[0m\"\n",
    "                else:\n",
    "                    formated = word\n",
    "                print(formated, end =' ')\n",
    "            print()\n",
    "#             print(preprocessedText)\n",
    "            ids = dataset.collate_fn([example])[0]['input_ids'][0]\n",
    "            pprintline('To BERT')\n",
    "            tokens = dataset.tokenizer.convert_ids_to_tokens(ids)\n",
    "            print(dataset.tokenizer.decode(ids))\n",
    "            pprintline('Pre-processed Text For Latex')\n",
    "            preprocessedText = example.text_a\n",
    "\n",
    "            for word in preprocessedText.split():\n",
    "                if word == \"Gene_A\":\n",
    "                    formated = \"\\colorbox{blue-wy}{Gene\\_A}\"\n",
    "                elif word == \"Gene_B\":\n",
    "                    formated = \"\\colorbox{mossgreen}{Gene\\_B}\"\n",
    "                elif word == \"Gene_S\":\n",
    "                    formated = \"\\colorbox{plum(web)}{Gene\\_S}\"\n",
    "                elif word == \"Gene_N\":\n",
    "                    formated = \"\\colorbox{peach}{Gene\\_N}\"\n",
    "                else:\n",
    "                    formated = word\n",
    "                print(formated, end =' ')\n",
    "            print()\n",
    "    cnt += 1\n",
    "    if cnt > 3:\n",
    "        break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Unfinished) Gene Distribution in Sentences 在句子中分布情况 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_document_process(document):\n",
    "    pmid = document['id']\n",
    "    relations = set()\n",
    "    genes = set()\n",
    "    text_li = []\n",
    "    passages = document['passages']\n",
    "    split_word = re.compile(r\"\\w+|\\S\")\n",
    "    for r in document['relations']:\n",
    "        relations.add((r['infons']['Gene1'], r['infons']['Gene2']))\n",
    "\n",
    "    for passage in passages:\n",
    "        anns = passage['annotations']\n",
    "        text = passage['text']\n",
    "        offset_p = passage['offset']\n",
    "        index = 0\n",
    "        if len(anns) == 0:\n",
    "            text_li.extend(split_word.findall(text))\n",
    "        else:\n",
    "            anns = Annotation.sortAnns(anns)\n",
    "            for ann in anns:\n",
    "                if Annotation.gettype(ann) == 'Gene':\n",
    "                    for infon_type in ann['infons']:\n",
    "                        if infon_type.lower() == 'ncbi gene':\n",
    "                            genes.add(ann['infons'][infon_type])\n",
    "                else:\n",
    "                    continue\n",
    "                for i, location in enumerate(ann['locations']):\n",
    "                    offset = location['offset']\n",
    "                    length = location['length']\n",
    "                    text_li.extend(split_word.findall(\n",
    "                        text[index:offset-offset_p]))\n",
    "                    if i == len(ann['locations']) - 1:\n",
    "                        ncbi_gene_id = Annotation.getNCBIID(ann)\n",
    "                        # for infon_type in ann['infons']:\n",
    "                            # if infon_type.lower() in ['ncbi gene', 'identifier']:\n",
    "                                # ncbi_gene_id = ann['infons'][infon_type]\n",
    "                        text_li.append(\"Gene_{}\".format(ncbi_gene_id))\n",
    "                    index = max(offset - offset_p + length, index)\n",
    "            text_li.extend(split_word.findall(text[index:]))\n",
    "    return pmid, text_li, genes, relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Crystal', 'structure', 'of', 'Gene_817592', 'from', 'Arabidopsis', 'thaliana', 'and', 'its', 'Gene_827837', 'binding', 'characterization', '']\n",
      "817592 exist\n",
      "827837 exist\n",
      "['', 'Microtubules', 'are', 'composed', 'of', 'polymerized', 'alpha', '/', 'Gene_827837', 'heterodimers', '']\n",
      "827837 exist\n",
      "['', 'Biogenesis', 'of', 'assembly', '-', 'competent', 'tubulin', 'dimers', 'is', 'a', 'complex', 'multistep', 'process', 'that', 'requires', 'sequential', 'actions', 'of', 'distinct', 'molecular', 'chaperones', 'and', 'cofactors', '']\n",
      "['', 'Gene_817592', '(', 'Gene_817592', ')', ',', 'which', 'captures', 'Gene_827837', 'during', 'the', 'folding', 'pathway', ',', 'has', 'been', 'identified', 'in', 'many', 'organisms', '']\n",
      "817592 exist\n",
      "827837 exist\n",
      "['', 'Here', ',', 'we', 'report', 'the', 'crystal', 'structure', 'of', 'Arabidopsis', 'thaliana', 'Gene_817592', '(', 'Gene_817592', ',', 'Gene_817592', ')', ',', 'which', 'forms', 'a', 'monomeric', 'three', '-', 'helix', 'bundle', '']\n",
      "817592 exist\n",
      "['', 'The', 'functional', 'binding', 'analysis', 'demonstrated', 'that', 'Gene_817592', 'interacts', 'with', 'Gene_827837', 'in', 'plant', '']\n",
      "817592 exist\n",
      "827837 exist\n",
      "['', 'Furthermore', ',', 'mutagenesis', 'studies', 'indicated', 'that', 'the', 'alpha', '-', 'helical', 'regions', 'of', 'Gene_817592', 'participate', 'in', 'Gene_827837', 'binding', '']\n",
      "817592 exist\n",
      "827837 exist\n",
      "['', 'Unlike', 'the', 'budding', 'yeast', 'Gene_817592', ',', 'the', 'two', 'loop', 'regions', 'of', 'Gene_817592', 'are', 'not', 'required', 'for', 'this', 'interaction', 'suggesting', 'a', 'distinct', 'binding', 'mechanism', 'of', 'Gene_817592', 'to', 'Gene_827837', 'in', 'plants', '']\n",
      "817592 exist\n",
      "827837 exist\n",
      "['']\n",
      "{'817592', '827837'}\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(os.environ.get('BC6PM_dir'), 'GNormPlus', 'withAnn-Result', 'PMtask_Relations_TrainingSet_r.json')) as f:\n",
    "    collection = json.load(f)\n",
    "    documents = collection['documents']\n",
    "pmid, text_li, genes, relations = train_document_process(documents[0])\n",
    "for sent in (' '.join(text_li)).split(\".\"):\n",
    "    sent_li = sent.split(' ')\n",
    "    print(sent_li)\n",
    "    for gene in genes:\n",
    "        if f\"Gene_{gene}\" in sent_li:\n",
    "            print(gene, 'exist')\n",
    "print(genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch-gpu]",
   "language": "python",
   "name": "conda-env-pytorch-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
